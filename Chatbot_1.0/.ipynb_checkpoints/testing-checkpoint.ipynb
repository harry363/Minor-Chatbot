{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _____TF-IDF libraries_____\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "# _____helper Libraries_____\n",
    "import pickle\n",
    "import csv\n",
    "import json\n",
    "import timeit\n",
    "import random\n",
    "import re\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_dataset = pd.read_csv(\"dialogueText.csv\")\n",
    "dataset = csv_dataset.iloc[500001:500500,1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev = []\n",
    "my_list = []\n",
    "q_a = {'question':'answer'}\n",
    "question = []\n",
    "answer = []\n",
    "q = \"\"\n",
    "a = \"\"\n",
    "previd=dataset[0][0]\n",
    "start=0\n",
    "i = int(0)\n",
    "\n",
    "row_count = dataset.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in tqdm(dataset):\n",
    "    if i < row_count and previd != dataset[i][0]:\n",
    "        for j in range(start,i):\n",
    "            from1 = dataset[j][2]\n",
    "            if (j==start) and dataset[j][3] == dataset[j][3]:\n",
    "                break\n",
    "            while (j < row_count) and (dataset[j][3] != dataset[j][3] or dataset[j][3] != from1):\n",
    "                q = q + str(dataset[j][4])\n",
    "                j = j+1\n",
    "\n",
    "            while j < row_count and dataset[j][3] == from1 :#tofrom\n",
    "                if a == \"\":\n",
    "                    a = str(dataset[j][4])\n",
    "                else:\n",
    "                    a = a + \"\\n\" + str(dataset[j][4])\n",
    "                j=j+1\n",
    "                \n",
    "            if(a != \"\"):\n",
    "                answer.append(a)\n",
    "\n",
    "            if(a != \"\" and q != \"\"):\n",
    "                question.append(q)\n",
    "            a=\"\"\n",
    "            q=\"\"\n",
    "            if j >= i:\n",
    "                break\n",
    "        previd = dataset[i][0]\n",
    "        start = i\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"i'm\", \"i am\", text)\n",
    "    text = re.sub(r\"he's\", \"he is\", text)\n",
    "    text = re.sub(r\"she's\", \"she is\", text)\n",
    "    text = re.sub(r\"that's\", \"that is\", text)\n",
    "    text = re.sub(r\"what's\", \"what is\", text)\n",
    "    text = re.sub(r\"where's\", \"where is\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"won't\", \"will not\", text)\n",
    "    text = re.sub(r\"can't\", \"cannot\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(userQuery):\n",
    "    ques = []\n",
    "    temp = clean_text(userQuery.lower())\n",
    "    for token in temp.split(' '):\n",
    "        t = str(token)\n",
    "        if nlp.vocab[t].is_stop:\n",
    "            pass\n",
    "    #         print('no')\n",
    "        else:\n",
    "            ques.append(t)\n",
    "    ques_list = ' '.join(ques)\n",
    "\n",
    "    ques2 = []\n",
    "    temp2 = nlp(ques_list)\n",
    "    for token2 in temp2:\n",
    "        \n",
    "        ques2.append(token2.lemma_)\n",
    "    ques_list = ' '.join(ques2)\n",
    "    return ques_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def talk_to_cb_primary(test_set_sentence, minimum_score , json_file_path , tfidf_vectorizer_pikle_path ,tfidf_matrix_train_pikle_path):\n",
    "    test_set = (test_set_sentence, \"\")\n",
    "\n",
    "    try:\n",
    "        f = open(tfidf_vectorizer_pikle_path, 'rb')\n",
    "        tfidf_vectorizer = pickle.load(f)\n",
    "        f.close()\n",
    "\n",
    "        f = open(tfidf_matrix_train_pikle_path, 'rb')\n",
    "        tfidf_matrix_train = pickle.load(f)\n",
    "        f.close()\n",
    "    except:\n",
    "        print(\"NO TRAINING\")\n",
    "        \n",
    "    tfidf_matrix_test = tfidf_vectorizer.transform(test_set)\n",
    "\n",
    "    cosine = cosine_similarity(tfidf_matrix_test, tfidf_matrix_train)\n",
    "\n",
    "    cosine = np.delete(cosine, 0)\n",
    "    max = cosine.max()\n",
    "    response_index = 0\n",
    "    if (max > minimum_score):\n",
    "        new_max = max - 0.01\n",
    "        list = np.where(cosine > new_max)\n",
    "        response_index = random.choice(list[0])\n",
    "    else :\n",
    "        return \"Apologies, I can't understand. My developers haven't trained me much! :(\" , 0\n",
    "           \n",
    "\n",
    "    j = 0\n",
    "\n",
    "    with open(json_file_path, \"r\") as sentences_file:\n",
    "        reader = json.load(sentences_file)\n",
    "        for row in reader:\n",
    "            j += 1  # we begin with 1 not 0 &    j is initialized by 0\n",
    "            if j == response_index:\n",
    "                return row[\"response\"], max\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def previous_chats(query):\n",
    "#     minimum_score = 0.7\n",
    "#     file = \"data.json\"\n",
    "#     tfidf_vectorizer_pikle_path = \"previous_tfidf_vectorizer.pickle\"\n",
    "#     tfidf_matrix_train_path = \"previous_tfidf_matrix_train.pickle\"\n",
    "#     query_response, score = talk_to_cb_primary(query , minimum_score , file , tfidf_vectorizer_pikle_path , tfidf_matrix_train_path)\n",
    "#     return query_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def previous_chats(query):\n",
    "    minimum_score = 0.7\n",
    "    file = \"data\\data.json\"\n",
    "    tfidf_vectorizer_pikle_path = \"data\\previous_tfidf_vectorizer.pickle\"\n",
    "    tfidf_matrix_train_path = \"data\\previous_tfidf_matrix_train.pickle\"\n",
    "    query_response, score = talk_to_cb_primary(query , minimum_score , file , tfidf_vectorizer_pikle_path , tfidf_matrix_train_path)\n",
    "    return query_response\n",
    "y_pred = []\n",
    "y_true = []\n",
    "y_true = answer\n",
    "\n",
    "i = int(0)\n",
    "#while 1:\n",
    "#     sent = input(\"Ask: \")\n",
    "for x in tqdm(question):\n",
    "    y_pred.append(previous_chats(x))\n",
    "    print(\"PREDICTED===> \" + y_pred[i])\n",
    "    print(\"ACTUAL   ===> \" + y_true[i])\n",
    "    i = i + 1\n",
    "\n",
    "#     sent = preprocess(sent)\n",
    "#     print(sent)\n",
    "\n",
    "precision = 9\n",
    "recall = 0\n",
    "f_score = 0\n",
    "\n",
    "\n",
    "precision = precision_score(y_true, y_pred, average='micro')\n",
    "# precision = precision_recall_fscore_support(y_true, y_pred, beta=1.0, \n",
    "#     labels=None, pos_label=1, average=None, warn_for=('precision', 'recall', 'f_score'), sample_weight=None)\n",
    "# print(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
